{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim \n",
    "\n",
    "from SmithZero import D2torchEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5bf090f490>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation \n",
    "* [ImageNet2012](https://github.com/DoranLyong/ImageNet2012-download)\n",
    "* [Pytorch Dataloader](https://pytorch.org/vision/stable/datasets.html#imagenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets \n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "# === data transformation === # \n",
    "normalize = T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "train_T = T.Compose([   T.RandomResizedCrop(224),\n",
    "                        T.RandomHorizontalFlip(), \n",
    "                        T.ToTensor(), \n",
    "                        normalize,\n",
    "                    ])\n",
    "\n",
    "test_T = T.Compose([T.Resize(256),\n",
    "                    T.CenterCrop(224),\n",
    "                    T.ToTensor(),\n",
    "                    normalize,\n",
    "                    ])                  \n",
    "\n",
    "\n",
    "# === dataset object === # \n",
    "train_dataset = datasets.ImageFolder(   root= './dataset/train',\n",
    "                                        transform= train_T, \n",
    "                                    )\n",
    "\n",
    "test_dataset = datasets.ImageFolder(    root= \"./dataset/val\", \n",
    "                                        transform= test_T,\n",
    "                                    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Batching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "trainloader = DataLoader(train_dataset,\n",
    "                        batch_size=256,\n",
    "                        shuffle=True, \n",
    "                        num_workers=4 \n",
    "                        )\n",
    "\n",
    "testloader = DataLoader(test_dataset,\n",
    "                        batch_size=256,\n",
    "                        num_workers=4\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```ImageNet2012``` has 1000-class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Transfer Learning in Practice (AlexNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import alexnet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# creating an instance of AlexNet without loading its pre-trained weights \n",
    "model = alexnet(pretrained=False) \n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking the structure, the architecture has three main elements:\n",
    "* ```features```, ```avgpool```, ```classifier``` \n",
    "    * the featurizer contains five typical convolutional blocks \n",
    "    * ```avgpool```: whatever the image size it gets as input, it will ```return a tensor with the desired size```\n",
    "    * the classifier has two hidden layers using 50% dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('',\n",
       "  AlexNet(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): ReLU(inplace=True)\n",
       "      (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Dropout(p=0.5, inplace=False)\n",
       "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    )\n",
       "  )),\n",
       " ('features',\n",
       "  Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )),\n",
       " ('features.0',\n",
       "  Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))),\n",
       " ('features.1', ReLU(inplace=True)),\n",
       " ('features.2',\n",
       "  MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)),\n",
       " ('features.3',\n",
       "  Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))),\n",
       " ('features.4', ReLU(inplace=True)),\n",
       " ('features.5',\n",
       "  MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)),\n",
       " ('features.6',\n",
       "  Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
       " ('features.7', ReLU(inplace=True)),\n",
       " ('features.8',\n",
       "  Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
       " ('features.9', ReLU(inplace=True)),\n",
       " ('features.10',\n",
       "  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
       " ('features.11', ReLU(inplace=True)),\n",
       " ('features.12',\n",
       "  MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)),\n",
       " ('avgpool', AdaptiveAvgPool2d(output_size=(6, 6))),\n",
       " ('classifier',\n",
       "  Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )),\n",
       " ('classifier.0', Dropout(p=0.5, inplace=False)),\n",
       " ('classifier.1', Linear(in_features=9216, out_features=4096, bias=True)),\n",
       " ('classifier.2', ReLU(inplace=True)),\n",
       " ('classifier.3', Dropout(p=0.5, inplace=False)),\n",
       " ('classifier.4', Linear(in_features=4096, out_features=4096, bias=True)),\n",
       " ('classifier.5', ReLU(inplace=True)),\n",
       " ('classifier.6', Linear(in_features=4096, out_features=1000, bias=True))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_modules())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Weights \n",
    "You can get the URL from the ```model_urls``` variable in ```torchvision.models.alexnet```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models.alexnet import model_urls\n",
    "from torch.hub import load_state_dict_from_url    # (ref) https://pytorch.org/docs/stable/hub.html\n",
    "\n",
    "# get pre-trained weights URL \n",
    "url = model_urls['alexnet']\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the pre-trained weights from the URL  to your local disk \n",
    "# (ref) https://www.programcreek.com/python/example/118276/torchvision.models.utils.load_state_dict_from_url\n",
    "state_dict = load_state_dict_from_url(  url, \n",
    "                                        model_dir = 'pretrained',\n",
    "                                        progress=True,\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['features.0.weight', 'features.0.bias', 'features.3.weight', 'features.3.bias', 'features.6.weight', 'features.6.bias', 'features.8.weight', 'features.8.bias', 'features.10.weight', 'features.10.bias', 'classifier.1.weight', 'classifier.1.bias', 'classifier.4.weight', 'classifier.4.bias', 'classifier.6.weight', 'classifier.6.bias'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading model \n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Freezing \n",
    "If you don't want to continue training the whole model : \n",
    "* you could pick it up where it was left off(중단) by the original authors\n",
    "* and ```resume training``` using your own dataset.\n",
    "\n",
    "```Freezing the model``` means that <b>it won't learn anymore</b>, that is, <b>its parameters/weights will not be updated anymore</b>.\n",
    "* what best characterizes a tensor representing a ```learnable parameter```? \n",
    "    * it requires ```gradients```\n",
    "    * So, we can make them stop learning anything by changing its boolean like a switch (ON/OFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 11, 11]), True\n",
      "torch.Size([64]), True\n",
      "torch.Size([192, 64, 5, 5]), True\n",
      "torch.Size([192]), True\n",
      "torch.Size([384, 192, 3, 3]), True\n",
      "torch.Size([384]), True\n",
      "torch.Size([256, 384, 3, 3]), True\n",
      "torch.Size([256]), True\n",
      "torch.Size([256, 256, 3, 3]), True\n",
      "torch.Size([256]), True\n",
      "torch.Size([4096, 9216]), True\n",
      "torch.Size([4096]), True\n",
      "torch.Size([4096, 4096]), True\n",
      "torch.Size([4096]), True\n",
      "torch.Size([1000, 4096]), True\n",
      "torch.Size([1000]), True\n"
     ]
    }
   ],
   "source": [
    "# Show the learnable parameters of the model \n",
    "for parameter in model.parameters():\n",
    "    print(f\"{parameter.size()}, {parameter.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set gradient as OFF \n",
    "\n",
    "def freeze_model(model):\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free your model \n",
    "freeze_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 11, 11]), False\n",
      "torch.Size([64]), False\n",
      "torch.Size([192, 64, 5, 5]), False\n",
      "torch.Size([192]), False\n",
      "torch.Size([384, 192, 3, 3]), False\n",
      "torch.Size([384]), False\n",
      "torch.Size([256, 384, 3, 3]), False\n",
      "torch.Size([256]), False\n",
      "torch.Size([256, 256, 3, 3]), False\n",
      "torch.Size([256]), False\n",
      "torch.Size([4096, 9216]), False\n",
      "torch.Size([4096]), False\n",
      "torch.Size([4096, 4096]), False\n",
      "torch.Size([4096]), False\n",
      "torch.Size([1000, 4096]), False\n",
      "torch.Size([1000]), False\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.parameters():\n",
    "    print(f\"{parameter.size()}, {parameter.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your model is frozen now :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing the top of the model (for fine-tune)\n",
    "* ```backbone``` : bottom \n",
    "* ```classifier``` : top "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Dropout(p=0.5, inplace=False)\n",
      "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Dropout(p=0.5, inplace=False)\n",
      "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./page_imgs/alexnet.png)\n",
    "\n",
    "*Source: Generated using Alexander Lenail’s [NN-SVG](http://alexlenail.me/NN-SVG/) and adapted by the author* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4096, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the top \n",
    "model.classifier[6]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```out_features=1000``` ⇒ nodes for 1000-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(11)\n",
    "\n",
    "#model.classifier[6] = nn.Linear(4096, 10)    # for cifar-10\n",
    "model.classifier[6] = nn.Linear(4096, 1000)  # for ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the <b>number of input features remains the same</b> since it still takes the\n",
    "output from the hidden layer that precedes it.\n",
    "\n",
    "(!) The <b>new output layer requires gradients by default</b>, but we can double-check it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight, False\n",
      "features.0.bias, False\n",
      "features.3.weight, False\n",
      "features.3.bias, False\n",
      "features.6.weight, False\n",
      "features.6.bias, False\n",
      "features.8.weight, False\n",
      "features.8.bias, False\n",
      "features.10.weight, False\n",
      "features.10.bias, False\n",
      "classifier.1.weight, False\n",
      "classifier.1.bias, False\n",
      "classifier.4.weight, False\n",
      "classifier.4.bias, False\n",
      "classifier.6.weight, True\n",
      "classifier.6.bias, True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters(): \n",
    "    print(f\"{name}, {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the top part by ```model.classifier[6]``` is set to ```True```.\n",
    "* These are the only things to be trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "## W&B setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === hyperparameter dict === # \n",
    "# you can receive with .yaml or .json \n",
    "\n",
    "hyperparams = dict(\n",
    "        seed=42, \n",
    "        epochs=50,\n",
    "        classes=1000,\n",
    "        batch_size=128,\n",
    "        n_workers=4,\n",
    "        learning_rate=3e-4,\n",
    "        dropout_p = 0.5,\n",
    "        dataset=\"ImageNet\",\n",
    "        architecture=\"AlexNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdoranlyong\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb \n",
    "\n",
    "wandb.login() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milky/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/html.py:12: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  warn(\"The `IPython.html` package has been deprecated since IPython 4.0. \"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/doranlyong/AlexNet-ImageNet/runs/2g00c144\" target=\"_blank\">dry-water-4</a></strong> to <a href=\"https://wandb.ai/doranlyong/AlexNet-ImageNet\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "proj_name = \"AlexNet-ImageNet\"\n",
    "\n",
    "wandb.init(project=proj_name, config=hyperparams)\n",
    "config = wandb.config "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(17)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='mean') \n",
    "optimizer = optim.Adam( model.parameters(), # (!) be sure to pass in the model.parameters() \n",
    "                        lr=config.learning_rate, \n",
    "                    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "AgentDL = D2torchEngine(model, loss_fn, optimizer)\n",
    "\n",
    "AgentDL.set_loaders(trainloader, testloader)\n",
    "AgentDL.set_wandb(wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [00:37<00:03,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 1.23E-03\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Learning Rate Range Test === # \n",
    "fig = AgentDL.lr_range_test(end_lr=1e-1, num_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === reset the optimzier === # \n",
    "#reset_optimizer = optim.Adam(  model.parameters(), lr=5.34e-3) \n",
    "#AgentDL.set_optimizer(reset_optimizer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set a scheduler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=20, T_mult=4, eta_min=1e-5, last_epoch= -1, verbose=False)\n",
    "\n",
    "AgentDL.set_lr_scheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AgentDL.optimizer == AgentDL.scheduler.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [7:44:37<51:22:46, 2126.06s/it]wandb: Network error (ReadTimeout), entering retry loop.\n",
      "100%|██████████| 100/100 [57:52:40<00:00, 2083.60s/it]\n"
     ]
    }
   ],
   "source": [
    "AgentDL.train(n_epochs=100, seed=config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0, 50],\n",
      "        [ 0, 50],\n",
      "        [ 0, 50],\n",
      "        ...,\n",
      "        [ 0, 50],\n",
      "        [ 0, 50],\n",
      "        [ 0, 50]])\n"
     ]
    }
   ],
   "source": [
    "# evaluating our model after training \n",
    "results = D2torchEngine.loader_apply(AgentDL.val_loader, AgentDL.correct, reduce=\"sum\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# More Effective Transfer Learning (p.582)\n",
    "To split the ```feature extraction``` and ```actual training``` phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f38f9a92a40eacf7671051530596ac31a08fa1747600811db2b78ca4cf9fd4a6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('py38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
