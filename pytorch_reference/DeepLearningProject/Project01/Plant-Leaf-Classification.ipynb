{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference \n",
    "* Reference to [DeepLearningProject's github](https://github.com/bjpublic/DeepLearningProject/tree/main/04_%EC%9E%91%EB%AC%BC_%EC%9E%8E_%EC%82%AC%EC%A7%84_%EC%A7%88%EB%B3%91_%EB%B6%84%EB%A5%98)\n",
    "* Reference to [pytorch.org - Transfer Learning](https://tutorials.pytorch.kr/beginner/transfer_learning_tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 목표 \n",
    "* Image Classification (잎 사진의 종류와 질병 유무 분류)\n",
    "* Transfer Learning에 대한 개념 확립 \n",
    "* 기본 CNN 모델의 학습 방식과 어떤 차이점이 있는지 숙지하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare Dataset \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. Dataset download \n",
    "* 원본 데이터: https://data.mendeley.com/datasets/tywbtsjrjv/1\n",
    "* 수정된 데이터: [bjpublic's github](https://github.com/bjpublic/DeepLearningProject/tree/main/04_%EC%9E%91%EB%AC%BC_%EC%9E%8E_%EC%82%AC%EC%A7%84_%EC%A7%88%EB%B3%91_%EB%B6%84%EB%A5%98)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2. Dataset split \n",
    "* 데이터를 train, val, test 디렉토리로 분할\n",
    "* 디렉토리 생성 방법; [pathlib.Path.mkdir](https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 데이터 분할을 위한 디렉토리 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import os.path as osp \n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 classes\n",
      "\n",
      "['Strawberry___healthy', 'Potato___Early_blight', 'Corn___Common_rust', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Apple___Cedar_apple_rust', 'Apple___Apple_scab', 'Tomato___healthy', 'Potato___healthy', 'Corn___Northern_Leaf_Blight', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Cherry___Powdery_mildew', 'Peach___healthy', 'Apple___healthy', 'Apple___Black_rot', 'Cherry___healthy', 'Peach___Bacterial_spot', 'Tomato___Tomato_mosaic_virus', 'Strawberry___Leaf_scorch', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Grape___Black_rot', 'Potato___Late_blight', 'Tomato___Leaf_Mold', 'Pepper,_bell___healthy', 'Tomato___Bacterial_spot', 'Corn___healthy', 'Tomato___Early_blight', 'Corn___Cercospora_leaf_spot Gray_leaf_spot', 'Grape___Esca_(Black_Measles)', 'Grape___healthy', 'Tomato___Late_blight', 'Tomato___Septoria_leaf_spot', 'Tomato___Target_Spot', 'Pepper,_bell___Bacterial_spot']\n"
     ]
    }
   ],
   "source": [
    "dpath = r'./dataset'\n",
    "class_list = os.listdir(dpath) \n",
    "print(f\"{len(class_list)} classes\", end=\"\\n\\n\")   # 분류 클래스 확인 \n",
    "print(f\"{class_list}\")   # 분류 클래스 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r'./processed'\n",
    "\n",
    "for split in ['train', 'val', 'test']: \n",
    "    for clss in class_list:\n",
    "        # train, val, test 용 디렉토리 생성 및 \n",
    "        # 각 split 폴더 하위에 클래스 목록 디렉토리 생성 \n",
    "        Path(osp.join(base_dir, split, clss)).mkdir(parents=True, exist_ok=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 데이터 분할과 클래스별 데이터 개수 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import math \n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_copy(img_frames:list, ori_path:str, dst_path:str): \n",
    "    for fname in img_frames: \n",
    "        src = osp.join(ori_path, fname) # 복사할 원본 파일의 경로 \n",
    "        dst = osp.join(dst_path, fname) # 복사 후 저장할 경로  \n",
    "        shutil.copyfile(src, dst) # src -> dst 경로로 복사 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clss in class_list:\n",
    "    ori_path = osp.join(dpath, clss) # 원본 데이터 경로 \n",
    "    fnames = os.listdir(ori_path) # 해당 디렉토리에 포함된 파일 목록을 가져옴 \n",
    "#    print(f\"num_data of {clss}: {len(fnames)}\")\n",
    "\n",
    "    # split each class data into 6:2:2\n",
    "    train_size = math.floor(len(fnames)*0.6)\n",
    "    val_size = math.floor(len(fnames)*0.2)\n",
    "    test_size = math.floor(len(fnames)*0.2)\n",
    "\n",
    "    train_fnames = fnames[:train_size]\n",
    "    val_fnames = fnames[train_size:(train_size + val_size)] \n",
    "    test_fnames = fnames[(train_size + val_size):\n",
    "                        (train_size + val_size + test_size)]  \n",
    "\n",
    "    # data copy \n",
    "    train_dst = osp.join(base_dir, 'train', clss)\n",
    "    data_copy(train_fnames, ori_path, train_dst)\n",
    "\n",
    "    val_dst = osp.join(base_dir, 'val', clss)\n",
    "    data_copy(val_fnames, ori_path, val_dst)\n",
    "\n",
    "    test_dst = osp.join(base_dir, 'test', clss)\n",
    "    data_copy(test_fnames, ori_path, test_dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.transforms as T \n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256 \n",
    "\n",
    "transform_base = T.Compose([\n",
    "    T.Resize((64,64)),\n",
    "    T.ToTensor(), # 이미지를 Tensor 형태로 변환 \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy', 'Cherry___Powdery_mildew', 'Cherry___healthy', 'Corn___Cercospora_leaf_spot Gray_leaf_spot', 'Corn___Common_rust', 'Corn___Northern_Leaf_Blight', 'Corn___healthy', 'Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy', 'Peach___Bacterial_spot', 'Peach___healthy', 'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Strawberry___Leaf_scorch', 'Strawberry___healthy', 'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Tomato_mosaic_virus', 'Tomato___healthy']\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ImageFolder(root=r\"./processed/train\", transform=transform_base)\n",
    "val_dataset = ImageFolder(root=r\"./processed/val\", transform=transform_base)\n",
    "test_dataset = ImageFolder(root=r\"./processed/test\", transform=transform_base)\n",
    "\n",
    "\n",
    "print(train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(  train_dataset, \n",
    "                            batch_size=BATCH_SIZE, \n",
    "                            shuffle=True, \n",
    "                            num_workers=4 )\n",
    "\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        shuffle=True, \n",
    "                        num_workers=4 )                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "imgs, labels = next(iter(train_loader)) \n",
    "print(imgs.size(), labels.size())\n",
    "print(imgs.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Baseline blocks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1. CNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class base_Net(nn.Module): \n",
    "    def __init__(self, num_classes:int=33): \n",
    "        super(base_Net, self).__init__() # nn.Module 내에 있는 메소드를 상속받기 위함 \n",
    "        \n",
    "        # backbone \n",
    "        # -------- \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1), \n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Dropout(p=0.25)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3,stride=1, padding=1), \n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Dropout(p=0.25)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3,stride=1, padding=1), \n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Dropout(p=0.25)\n",
    "        )\n",
    "\n",
    "        # building classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(4096, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "            )\n",
    "\n",
    "        # init. weights \n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x:torch.Tensor): \n",
    "        assert x.ndimension() == 4, f\"input tensor should be 4D, but got {x.ndimension()}D\"\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        \n",
    "        x = x.view(-1, 64*8*8) # (B,64,8,8) -> (B, 4096)        \n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x \n",
    "    \n",
    "    def _initialize_weights(self): \n",
    "        for m in self.modules(): \n",
    "            if isinstance(m, nn.Conv2d): \n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels # 파라미터 개수 \n",
    "                m.weight.data.normal_(0,  math.sqrt(2. / n))\n",
    "                if m.bias is not None: \n",
    "                    m.bias.data.zero_() \n",
    "            elif isinstance(m, nn.BatchNorm2d):                     \n",
    "                m.weight.data.fill_(1)\n",
    "                m.weight.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):                                     \n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 33])\n"
     ]
    }
   ],
   "source": [
    "model = base_Net(num_classes= len(class_list)).to(device)\n",
    "\n",
    "x = torch.randn(4, 3, 64, 64).to(device)\n",
    "\n",
    "logit = model(x)\n",
    "print(logit.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2. train loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, loss_fn): \n",
    "    model.train() \n",
    "    train_loss = 0.0 \n",
    "    train_correct = 0\n",
    "\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader): \n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        # forward \n",
    "        # --------\n",
    "        logit = model(data) \n",
    "        _, argmax_idx = torch.max(logit, dim=1) \n",
    "        loss = loss_fn(logit, labels) \n",
    "        \n",
    "        # backward & step  \n",
    "        # ---------------\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward() \n",
    "        optimizer.step() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3. evaluation loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, loss_fn): \n",
    "    model.eval() \n",
    "    total_loss = 0.0 \n",
    "    total_correct = 0\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for batch_idx, (data, labels) in enumerate(dataloader): \n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            # forward \n",
    "            # --------\n",
    "            logit = model(data)\n",
    "            _, argmax_idx = torch.max(logit, dim=1) \n",
    "            loss = loss_fn(logit, labels) \n",
    "\n",
    "            # === accumulate batch loss & accuracy \n",
    "            total_loss += loss.item()\n",
    "            total_correct += torch.sum(argmax_idx == labels.data).item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader.dataset) \n",
    "        acc = 100. * total_correct / len(dataloader.dataset) \n",
    "    \n",
    "    return avg_loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Run model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import copy \n",
    "\n",
    "import torch.optim as optim \n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4) \n",
    "\n",
    "# learning rate scheduler. \n",
    "exp_lr_scheduler = StepLR(  optimizer, # optim object \n",
    "                            step_size=7,\n",
    "                            gamma=0.1\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- epoch 1 ----------------\n",
      "train Loss: 0.0126, Accuracy: 15.73%\n",
      "val Loss: 0.0129, Accuracy: 15.83%\n",
      "Completed in 0m 19s\n",
      "-------------- epoch 2 ----------------\n",
      "train Loss: 0.0097, Accuracy: 29.98%\n",
      "val Loss: 0.0099, Accuracy: 30.23%\n",
      "Completed in 0m 20s\n",
      "-------------- epoch 3 ----------------\n",
      "train Loss: 0.0083, Accuracy: 38.43%\n",
      "val Loss: 0.0085, Accuracy: 38.34%\n",
      "Completed in 0m 20s\n",
      "-------------- epoch 4 ----------------\n",
      "train Loss: 0.0075, Accuracy: 44.70%\n",
      "val Loss: 0.0077, Accuracy: 44.97%\n",
      "Completed in 0m 20s\n",
      "-------------- epoch 5 ----------------\n",
      "train Loss: 0.0067, Accuracy: 50.89%\n",
      "val Loss: 0.0069, Accuracy: 50.63%\n",
      "Completed in 0m 20s\n",
      "-------------- epoch 6 ----------------\n",
      "train Loss: 0.0063, Accuracy: 52.69%\n",
      "val Loss: 0.0065, Accuracy: 52.77%\n",
      "Completed in 0m 19s\n",
      "-------------- epoch 7 ----------------\n",
      "train Loss: 0.0058, Accuracy: 56.04%\n",
      "val Loss: 0.0060, Accuracy: 56.33%\n",
      "Completed in 0m 20s\n",
      "-------------- epoch 8 ----------------\n",
      "train Loss: 0.0058, Accuracy: 56.22%\n",
      "val Loss: 0.0059, Accuracy: 56.00%\n",
      "Completed in 0m 20s\n",
      "-------------- epoch 9 ----------------\n",
      "train Loss: 0.0057, Accuracy: 56.28%\n",
      "val Loss: 0.0059, Accuracy: 56.06%\n",
      "Completed in 0m 20s\n",
      "-------------- epoch 10 ----------------\n",
      "train Loss: 0.0057, Accuracy: 56.77%\n",
      "val Loss: 0.0059, Accuracy: 56.70%\n",
      "Completed in 0m 20s\n",
      "-------------- epoch 11 ----------------\n",
      "train Loss: 0.0057, Accuracy: 56.59%\n",
      "val Loss: 0.0058, Accuracy: 56.40%\n",
      "Completed in 0m 20s\n",
      "-------------- epoch 12 ----------------\n",
      "train Loss: 0.0056, Accuracy: 56.94%\n",
      "val Loss: 0.0058, Accuracy: 56.80%\n",
      "Completed in 0m 20s\n",
      "-------------- epoch 13 ----------------\n",
      "train Loss: 0.0055, Accuracy: 57.88%\n",
      "val Loss: 0.0057, Accuracy: 57.54%\n",
      "Completed in 0m 20s\n",
      "-------------- epoch 14 ----------------\n",
      "train Loss: 0.0056, Accuracy: 56.88%\n",
      "val Loss: 0.0057, Accuracy: 56.65%\n",
      "Completed in 0m 20s\n",
      "-------------- epoch 15 ----------------\n",
      "train Loss: 0.0055, Accuracy: 57.22%\n",
      "val Loss: 0.0057, Accuracy: 57.08%\n",
      "Completed in 0m 20s\n",
      "-------------- epoch 16 ----------------\n",
      "train Loss: 0.0055, Accuracy: 57.29%\n",
      "val Loss: 0.0057, Accuracy: 57.13%\n",
      "Completed in 0m 19s\n",
      "-------------- epoch 17 ----------------\n",
      "train Loss: 0.0055, Accuracy: 57.30%\n",
      "val Loss: 0.0057, Accuracy: 57.14%\n",
      "Completed in 0m 20s\n",
      "-------------- epoch 18 ----------------\n",
      "train Loss: 0.0055, Accuracy: 57.29%\n",
      "val Loss: 0.0057, Accuracy: 57.05%\n",
      "Completed in 0m 20s\n",
      "-------------- epoch 19 ----------------\n",
      "train Loss: 0.0055, Accuracy: 57.31%\n",
      "val Loss: 0.0057, Accuracy: 57.10%\n",
      "Completed in 0m 20s\n",
      "-------------- epoch 20 ----------------\n",
      "train Loss: 0.0055, Accuracy: 57.19%\n",
      "val Loss: 0.0057, Accuracy: 56.99%\n",
      "Completed in 0m 20s\n",
      "-------------- epoch 21 ----------------\n",
      "train Loss: 0.0055, Accuracy: 57.55%\n",
      "val Loss: 0.0057, Accuracy: 57.40%\n",
      "Completed in 0m 20s\n",
      "-------------- epoch 22 ----------------\n",
      "train Loss: 0.0055, Accuracy: 57.55%\n",
      "val Loss: 0.0057, Accuracy: 57.37%\n",
      "Completed in 0m 19s\n",
      "-------------- epoch 23 ----------------\n",
      "train Loss: 0.0055, Accuracy: 57.56%\n",
      "val Loss: 0.0057, Accuracy: 57.32%\n",
      "Completed in 0m 20s\n",
      "-------------- epoch 24 ----------------\n",
      "train Loss: 0.0055, Accuracy: 57.55%\n",
      "val Loss: 0.0057, Accuracy: 57.30%\n",
      "Completed in 0m 20s\n",
      "-------------- epoch 25 ----------------\n",
      "train Loss: 0.0055, Accuracy: 57.54%\n",
      "val Loss: 0.0057, Accuracy: 57.28%\n",
      "Completed in 0m 20s\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 25 \n",
    "\n",
    "best_acc = 0.0 \n",
    "best_model_wts = copy.deepcopy(model.state_dict()) \n",
    "\n",
    "for epoch in range(1, EPOCHS+1): \n",
    "    since = time.time() \n",
    "\n",
    "    # Train \n",
    "    # ---------\n",
    "    train(model, train_loader, optimizer, loss_fn)\n",
    "    train_loss, train_acc = evaluate(model, train_loader, loss_fn)\n",
    "\n",
    "                                                                \n",
    "    # Schedule the learning rate for next the epoch of training.\n",
    "    # ---------------------------------------------------------\n",
    "    exp_lr_scheduler.step()  \n",
    "\n",
    "    # Validation \n",
    "    # ------------\n",
    "    val_loss, val_acc = evaluate(model, val_loader, loss_fn)\n",
    "\n",
    "\n",
    "    # New best \n",
    "    # -------------\n",
    "    if val_acc > best_acc: \n",
    "        best_acc = val_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        # save the model parameters \n",
    "        torch.save(best_model_wts, \"./new_baseline_best.pth\")\n",
    "\n",
    "    # Log \n",
    "    # ---------- \n",
    "    time_elapsed = time.time() - since \n",
    "    print(f'-------------- epoch {epoch} ----------------')\n",
    "    print(f'train Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%')   \n",
    "    print(f'val Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%')\n",
    "    print(f'Completed in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 4. Transfer Learning \n",
    "* ResNet50 모델을 불러온 후, '작물 잎을 분류하는 task'에 맞춰서 Fine-Tuning 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1. DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': T.Compose([T.Resize([64,64]), \n",
    "        T.RandomHorizontalFlip(p=0.5), T.RandomVerticalFlip(p=0.5),  \n",
    "        T.RandomCrop(52), T.ToTensor(), \n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]),\n",
    "    \n",
    "    'val': T.Compose([T.Resize([64,64]),  \n",
    "        T.RandomCrop(52), T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy', 'Cherry___Powdery_mildew', 'Cherry___healthy', 'Corn___Cercospora_leaf_spot Gray_leaf_spot', 'Corn___Common_rust', 'Corn___Northern_Leaf_Blight', 'Corn___healthy', 'Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy', 'Peach___Bacterial_spot', 'Peach___healthy', 'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Strawberry___Leaf_scorch', 'Strawberry___healthy', 'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Tomato_mosaic_virus', 'Tomato___healthy']\n"
     ]
    }
   ],
   "source": [
    "data_dir = r\"./processed\"\n",
    "\n",
    "image_datasets = {x: ImageFolder(root=osp.join(data_dir, x), transform=data_transforms[x]) \n",
    "                                                                for x in ['train', 'val']} \n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=4) \n",
    "                                                                        for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}          \n",
    "\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2. Get Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "print(resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-3. Model Freezing \n",
    "* learnable parameters 가 업데이트 되지 않도록 ```requires_grad``` 를 OFF 한다. \n",
    "* ```children()``` 메소드는 자식 모듈을 반복 가능한 객체로 반환한다. \n",
    "    * ```resnet.children()``` 은 생성한 resnet 모델의 모든 Layer 정보를 담고 있음. \n",
    "    * 아래 freeze_model() 함수는 ResNet50에 존재하는 10개의 Layer 중에서 1~5번 Layer의 파라미터만 업데이트되도록 고정함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_model(model): \n",
    "    ct = 0 \n",
    "    for child in model.children():  \n",
    "        ct += 1 \n",
    "        if ct < 6: \n",
    "            for parameter in child.parameters(): \n",
    "                parameter.requires_grad = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_model(resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-4. Replacing the top of the model (for fine-tune)\n",
    "* ```backbone``` : bottom \n",
    "* ```classifier``` : top "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2048, out_features=33, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(resnet.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(11) \n",
    "\n",
    "resnet.fc = nn.Linear(2048, len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-5. Training \n",
    "* ```filter(lambda p: p.requires_grad, resnet.parameters()``` \n",
    "    * 모델의 일부 Layer의 파라미터만 업데이트하기 위해서 ```requires_grad=True```로 설정된 Layer의 파라미터만 반환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, resnet.parameters()), lr=1e-4) \n",
    "\n",
    "# learning rate scheduler. \n",
    "exp_lr_scheduler = StepLR(  optimizer, # optim object \n",
    "                            step_size=7,\n",
    "                            gamma=0.1\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- epoch 1 ----------------\n",
      "learning rate: [0.0001]\n",
      "train Loss: 0.0093, Accuracy: 42.84%\n",
      "val Loss: 0.0096, Accuracy: 42.37%\n",
      "Best val Acc: 42.3708\n",
      "Completed in 0m 21s\n",
      "-------------- epoch 2 ----------------\n",
      "learning rate: [0.0001]\n",
      "train Loss: 0.0070, Accuracy: 60.43%\n",
      "val Loss: 0.0073, Accuracy: 58.87%\n",
      "Best val Acc: 58.8684\n",
      "Completed in 0m 20s\n",
      "-------------- epoch 3 ----------------\n",
      "learning rate: [0.0001]\n",
      "train Loss: 0.0058, Accuracy: 67.39%\n",
      "val Loss: 0.0061, Accuracy: 65.53%\n",
      "Best val Acc: 65.5276\n",
      "Completed in 0m 20s\n",
      "-------------- epoch 4 ----------------\n",
      "learning rate: [0.0001]\n",
      "train Loss: 0.0051, Accuracy: 70.88%\n",
      "val Loss: 0.0054, Accuracy: 68.68%\n",
      "Best val Acc: 68.6819\n",
      "Completed in 0m 19s\n",
      "-------------- epoch 5 ----------------\n",
      "learning rate: [0.0001]\n",
      "train Loss: 0.0045, Accuracy: 73.22%\n",
      "val Loss: 0.0049, Accuracy: 70.72%\n",
      "Best val Acc: 70.7222\n",
      "Completed in 0m 19s\n",
      "-------------- epoch 6 ----------------\n",
      "learning rate: [0.0001]\n",
      "train Loss: 0.0042, Accuracy: 75.11%\n",
      "val Loss: 0.0045, Accuracy: 72.47%\n",
      "Best val Acc: 72.4747\n",
      "Completed in 0m 19s\n",
      "-------------- epoch 7 ----------------\n",
      "learning rate: [1e-05]\n",
      "train Loss: 0.0039, Accuracy: 76.41%\n",
      "val Loss: 0.0043, Accuracy: 72.93%\n",
      "Best val Acc: 72.9253\n",
      "Completed in 0m 19s\n",
      "-------------- epoch 8 ----------------\n",
      "learning rate: [1e-05]\n",
      "train Loss: 0.0039, Accuracy: 76.62%\n",
      "val Loss: 0.0042, Accuracy: 73.41%\n",
      "Best val Acc: 73.4134\n",
      "Completed in 0m 19s\n",
      "-------------- epoch 9 ----------------\n",
      "learning rate: [1e-05]\n",
      "train Loss: 0.0038, Accuracy: 76.67%\n",
      "val Loss: 0.0042, Accuracy: 73.51%\n",
      "Best val Acc: 73.5136\n",
      "Completed in 0m 20s\n",
      "-------------- epoch 10 ----------------\n",
      "learning rate: [1e-05]\n",
      "train Loss: 0.0038, Accuracy: 76.84%\n",
      "val Loss: 0.0042, Accuracy: 73.64%\n",
      "Best val Acc: 73.6388\n",
      "Completed in 0m 19s\n",
      "-------------- epoch 11 ----------------\n",
      "learning rate: [1e-05]\n",
      "train Loss: 0.0038, Accuracy: 76.86%\n",
      "val Loss: 0.0042, Accuracy: 73.55%\n",
      "Best val Acc: 73.6388\n",
      "Completed in 0m 19s\n",
      "-------------- epoch 12 ----------------\n",
      "learning rate: [1e-05]\n",
      "train Loss: 0.0038, Accuracy: 77.05%\n",
      "val Loss: 0.0041, Accuracy: 73.89%\n",
      "Best val Acc: 73.8891\n",
      "Completed in 0m 19s\n",
      "-------------- epoch 13 ----------------\n",
      "learning rate: [1e-05]\n",
      "train Loss: 0.0037, Accuracy: 77.26%\n",
      "val Loss: 0.0041, Accuracy: 73.86%\n",
      "Best val Acc: 73.8891\n",
      "Completed in 0m 19s\n",
      "-------------- epoch 14 ----------------\n",
      "learning rate: [1.0000000000000002e-06]\n",
      "train Loss: 0.0037, Accuracy: 77.41%\n",
      "val Loss: 0.0041, Accuracy: 73.96%\n",
      "Best val Acc: 73.9642\n",
      "Completed in 0m 19s\n",
      "-------------- epoch 15 ----------------\n",
      "learning rate: [1.0000000000000002e-06]\n",
      "train Loss: 0.0037, Accuracy: 77.33%\n",
      "val Loss: 0.0041, Accuracy: 74.01%\n",
      "Best val Acc: 74.0143\n",
      "Completed in 0m 19s\n",
      "-------------- epoch 16 ----------------\n",
      "learning rate: [1.0000000000000002e-06]\n",
      "train Loss: 0.0037, Accuracy: 77.41%\n",
      "val Loss: 0.0041, Accuracy: 74.00%\n",
      "Best val Acc: 74.0143\n",
      "Completed in 0m 19s\n",
      "-------------- epoch 17 ----------------\n",
      "learning rate: [1.0000000000000002e-06]\n",
      "train Loss: 0.0037, Accuracy: 77.38%\n",
      "val Loss: 0.0041, Accuracy: 73.75%\n",
      "Best val Acc: 74.0143\n",
      "Completed in 0m 19s\n",
      "-------------- epoch 18 ----------------\n",
      "learning rate: [1.0000000000000002e-06]\n",
      "train Loss: 0.0037, Accuracy: 77.34%\n",
      "val Loss: 0.0041, Accuracy: 73.76%\n",
      "Best val Acc: 74.0143\n",
      "Completed in 0m 19s\n",
      "-------------- epoch 19 ----------------\n",
      "learning rate: [1.0000000000000002e-06]\n",
      "train Loss: 0.0037, Accuracy: 77.22%\n",
      "val Loss: 0.0041, Accuracy: 73.98%\n",
      "Best val Acc: 74.0143\n",
      "Completed in 0m 19s\n",
      "-------------- epoch 20 ----------------\n",
      "learning rate: [1.0000000000000002e-06]\n",
      "train Loss: 0.0037, Accuracy: 77.50%\n",
      "val Loss: 0.0041, Accuracy: 74.13%\n",
      "Best val Acc: 74.1269\n",
      "Completed in 0m 19s\n",
      "-------------- epoch 21 ----------------\n",
      "learning rate: [1.0000000000000002e-07]\n",
      "train Loss: 0.0037, Accuracy: 77.36%\n",
      "val Loss: 0.0041, Accuracy: 74.15%\n",
      "Best val Acc: 74.1520\n",
      "Completed in 0m 19s\n",
      "-------------- epoch 22 ----------------\n",
      "learning rate: [1.0000000000000002e-07]\n",
      "train Loss: 0.0037, Accuracy: 77.39%\n",
      "val Loss: 0.0041, Accuracy: 74.03%\n",
      "Best val Acc: 74.1520\n",
      "Completed in 0m 19s\n",
      "-------------- epoch 23 ----------------\n",
      "learning rate: [1.0000000000000002e-07]\n",
      "train Loss: 0.0037, Accuracy: 77.50%\n",
      "val Loss: 0.0041, Accuracy: 74.03%\n",
      "Best val Acc: 74.1520\n",
      "Completed in 0m 19s\n",
      "-------------- epoch 24 ----------------\n",
      "learning rate: [1.0000000000000002e-07]\n",
      "train Loss: 0.0037, Accuracy: 77.28%\n",
      "val Loss: 0.0041, Accuracy: 74.24%\n",
      "Best val Acc: 74.2396\n",
      "Completed in 0m 19s\n",
      "-------------- epoch 25 ----------------\n",
      "learning rate: [1.0000000000000002e-07]\n",
      "train Loss: 0.0037, Accuracy: 77.51%\n",
      "val Loss: 0.0041, Accuracy: 73.95%\n",
      "Best val Acc: 74.2396\n",
      "Completed in 0m 19s\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 25 \n",
    "\n",
    "best_acc = 0.0 \n",
    "best_model_wts = copy.deepcopy(resnet.state_dict()) \n",
    "\n",
    "for epoch in range(1, EPOCHS+1): \n",
    "    since = time.time() \n",
    "\n",
    "    # Train \n",
    "    # ---------\n",
    "    train(resnet , train_loader, optimizer, loss_fn)\n",
    "    train_loss, train_acc = evaluate(resnet , train_loader, loss_fn)\n",
    "\n",
    "                                                                \n",
    "    # Schedule the learning rate for next the epoch of training.\n",
    "    # ---------------------------------------------------------\n",
    "    exp_lr_scheduler.step()  \n",
    "    lr = [x['lr'] for x in optimizer.param_groups]\n",
    "\n",
    "    # Validation \n",
    "    # ------------\n",
    "    val_loss, val_acc = evaluate(resnet , val_loader, loss_fn)\n",
    "\n",
    "\n",
    "    # New best \n",
    "    # -------------\n",
    "    if val_acc > best_acc: \n",
    "        best_acc = val_acc\n",
    "        best_model_wts = copy.deepcopy(resnet.state_dict())\n",
    "\n",
    "        # save the model parameters \n",
    "        torch.save(best_model_wts, \"./new_resnet_best.pth\")\n",
    "\n",
    "    # Log \n",
    "    # ---------- \n",
    "    time_elapsed = time.time() - since \n",
    "    print(f'-------------- epoch {epoch} ----------------')\n",
    "    print(f\"learning rate: {lr}\")\n",
    "    print(f'train Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%')   \n",
    "    print(f'val Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%')\n",
    "    print(f\"Best val Acc: {best_acc:.4f}\")\n",
    "    print(f'Completed in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 5. 모델 평가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_test(model, dataloader): \n",
    "    model.eval() \n",
    "    total_correct = 0\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for batch_idx, (data, labels) in enumerate(dataloader): \n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            # forward \n",
    "            # --------\n",
    "            logit = model(data)\n",
    "            _, argmax_idx = torch.max(logit, dim=1) \n",
    "            \n",
    "            # === accumulate accuracy \n",
    "            total_correct += torch.sum(argmax_idx == labels.data).item()\n",
    "\n",
    "        acc = 100. * total_correct / len(dataloader.dataset) \n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-1. Baseline CNN 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_base = T.Compose([T.Resize([64,64]), T.ToTensor()])\n",
    "test_base = ImageFolder(root='./processed/test',transform=transform_base)  \n",
    "test_loader_base = DataLoader(test_base, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline test acc: 56.8657% \n"
     ]
    }
   ],
   "source": [
    "baseline = torch.load('new_baseline_best.pth') \n",
    "\n",
    "custom_model = base_Net(num_classes= len(class_list)).to(device)\n",
    "custom_model.load_state_dict(baseline)\n",
    "custom_model = custom_model.to(device)\n",
    "\n",
    "\n",
    "test_accuracy = inference_test(custom_model, test_loader_base)\n",
    "\n",
    "print(f'baseline test acc: {test_accuracy:.4f}% ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-2. Transfer Learning 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_resNet = T.Compose([\n",
    "        T.Resize([64,64]),  \n",
    "        T.RandomCrop(52), T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "    ])\n",
    "    \n",
    "test_resNet = ImageFolder(root='./processed/test', transform=transform_resNet) \n",
    "test_loader_resNet = DataLoader(test_resNet, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet test acc: 73.6012%\n"
     ]
    }
   ],
   "source": [
    "# prepare model \n",
    "resnet_test = models.resnet50(pretrained=False)\n",
    "resnet_test.fc = nn.Linear(2048, len(class_names))\n",
    "\n",
    "# load state_dict \n",
    "resnet_states = torch.load('new_resnet_best.pth') \n",
    "\n",
    "resnet_test.load_state_dict(resnet_states)\n",
    "resnet_test = resnet_test.to(device) \n",
    "\n",
    "\n",
    "# inference \n",
    "resnet_accuracy = inference_test(resnet_test , test_loader_base)\n",
    "print(f'resnet test acc: {resnet_accuracy:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f38f9a92a40eacf7671051530596ac31a08fa1747600811db2b78ca4cf9fd4a6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
