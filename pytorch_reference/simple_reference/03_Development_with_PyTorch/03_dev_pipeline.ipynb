{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DoranLyong/Awesome-Tensor-Architecture/blob/main/pytorch_reference/simple_reference/03_Development_with_PyTorch/03_dev_pipeline.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do I need? - the basic deep learning development process (p.53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n- data preparation\\n- build a model \\n- train the model \\n- test the trained model to check performance \\n- For improving, tweak hyperparameters and retrain \\n- finally, deploy your model for any service \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "- data preparation\n",
    "- build a model \n",
    "- train the model \n",
    "- test the trained model to check performance \n",
    "- For improving, tweak hyperparameters and retrain \n",
    "- finally, deploy your model for any service \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0+cu111\n",
      "0.10.0+cu111\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision \n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading (p.55)\n",
    "* CIFAR-10 from ```torchvision.datasets```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "\"\"\"\n",
    "    Dataset class returns a dataset object that includes : \n",
    "        - data and \n",
    "        - information about the data \n",
    "\"\"\"\n",
    "train_data = CIFAR10(   root= \"./train\", \n",
    "                        train=True, \n",
    "                        download=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_check_integrity',\n",
       " '_format_transform_repr',\n",
       " '_is_protocol',\n",
       " '_load_meta',\n",
       " '_repr_indent',\n",
       " 'base_folder',\n",
       " 'class_to_idx',\n",
       " 'classes',\n",
       " 'data',\n",
       " 'download',\n",
       " 'extra_repr',\n",
       " 'filename',\n",
       " 'meta',\n",
       " 'root',\n",
       " 'target_transform',\n",
       " 'targets',\n",
       " 'test_list',\n",
       " 'tgz_md5',\n",
       " 'train',\n",
       " 'train_list',\n",
       " 'transform',\n",
       " 'transforms',\n",
       " 'url']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(train_data) # show class attributes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: ./train\n",
      "    Split: Train\n"
     ]
    }
   ],
   "source": [
    "# general information of the dataset object \n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "# length of the data \n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# shape of data \n",
    "print(type(train_data.data))\n",
    "print(train_data.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "# targets in index(= labels)\n",
    "print(type(train_data.targets))\n",
    "print(len(train_data.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "# class names \n",
    "print(train_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n"
     ]
    }
   ],
   "source": [
    "# class names to index values \n",
    "print(train_data.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access a data sample (p.57)\n",
    "* using an index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "one_instance = train_data[0]\n",
    "\n",
    "print(type(one_instance)) \n",
    "print(len(one_instance))\n",
    "\n",
    "data, label = one_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.Image.Image'>\n",
      "<class 'int'>\n",
      "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F1DD9194A60>\n"
     ]
    }
   ],
   "source": [
    "print(type(data))\n",
    "print(type(label))\n",
    "print(data) # 32x32 size, RGB image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1dcc689970>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the data \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.imshow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "6\n",
      "frog\n"
     ]
    }
   ],
   "source": [
    "# examine the label \n",
    "print(type(label))\n",
    "print(label)  \n",
    "print(train_data.classes[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likewise, call test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_data = CIFAR10(root='./test', \n",
    "                    train=False, \n",
    "                    download=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CIFAR10\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./test\n",
      "    Split: Test\n",
      "10000\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(test_data)\n",
    "\n",
    "print(len(test_data))\n",
    "print(test_data.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transforms (p.59)\n",
    "* load the dataset object applying transforms to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms as T \n",
    "\n",
    "train_T = T.Compose([ T.RandomCrop(32, padding=4),\n",
    "                      T.RandomHorizontalFlip(), \n",
    "                      T.ToTensor(), \n",
    "                      T.Normalize( mean= (0.4914, 0.4822, 0.4465),\n",
    "                                   std=(0.2023, 0.1994, 0.2010)),\n",
    "                    ])\n",
    "\n",
    "train_data = CIFAR10(   root=\"./train\",\n",
    "                        train=True, \n",
    "                        download=True, \n",
    "                        transform=train_T, # set the transform parameter when creating the dataset \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: ./train\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomCrop(size=(32, 32), padding=4)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomCrop(size=(32, 32), padding=4)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(train_data.transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "data, label = train_data[0]\n",
    "\n",
    "print(type(data))\n",
    "print(data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1dcc54b6d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data.permute(1, 2, 0)) # (C, H, W) -> (H, W, C) for visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likewise, call test data but different transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_T = T.Compose([  T.ToTensor(),\n",
    "                      T.Normalize( mean=(0.4914, 0.4822, 0.4465),\n",
    "                                   std=(0.2023, 0.1994, 0.2010))\n",
    "                   ])\n",
    "\n",
    "test_data = CIFAR10(root=\"./test\",\n",
    "                    train=False, \n",
    "                    transform=test_T, \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CIFAR10\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./test\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Batching (p.62)\n",
    "* sending data in batches for model input in PyTorch \n",
    "* use the ```torch.utils.data.DataLoader``` for batch processing \n",
    "* refer to p.67 for more advanced usage \n",
    "\n",
    "※ built-in ```DataLoader``` generates an iterable for your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "\n",
    "trainloader = DataLoader( train_data,  # dataset object \n",
    "                          batch_size=16, \n",
    "                          shuffle=True, \n",
    "                          num_workers=3,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 32, 32])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "    Simply check the dataloader object.\n",
    "    Retrieve a batch of sampels from the trainloader: \n",
    "\n",
    "        - iter() to cast the trainloader to an iterator \n",
    "        - next() to iterate over the data one more time \n",
    "\"\"\"\n",
    "\n",
    "data_batch, labels_batch = next(iter(trainloader)) \n",
    "\n",
    "print(data_batch.size())\n",
    "print(labels_batch.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = DataLoader( test_data, \n",
    "                         batch_size=16, \n",
    "                          shuffle=False,\n",
    "                          num_workers=3,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "## Model Design - using existing & pre-trained models (p.69)\n",
    "* from ```torchvision.models``` \n",
    "* from ```torch.hub```  (docker hub 같은 것)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_buffers', '_call_impl', '_forward_hooks', '_forward_pre_hooks', '_get_backward_hooks', '_get_name', '_initialize_weights', '_is_full_backward_hook', '_load_from_state_dict', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_version', 'add_module', 'apply', 'avgpool', 'bfloat16', 'buffers', 'children', 'classifier', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'features', 'float', 'forward', 'get_buffer', 'get_parameter', 'get_submodule', 'half', 'load_state_dict', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_parameter', 'requires_grad_', 'share_memory', 'state_dict', 'to', 'to_empty', 'train', 'training', 'type', 'xpu', 'zero_grad']\n",
      "Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "print(dir(model))\n",
    "print(model.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/doranlyong/.cache/torch/hub/nvidia_DeepLearningExamples_torchhub\n",
      "/home/doranlyong/.cache/torch/hub/nvidia_DeepLearningExamples_torchhub/PyTorch/SpeechSynthesis/Tacotron2/waveglow/model.py:55: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
      "The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
      "Q, R = torch.qr(A, some)\n",
      "should be replaced with\n",
      "Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at  /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:1940.)\n",
      "  W = torch.qr(torch.FloatTensor(c, c).normal_())[0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 'Pytorch Hub' is another excellent resource for existing and pretrained PyTorch models. \n",
    "    Load models from another repository using the torch.hub.load() API. \n",
    "\"\"\"\n",
    "\n",
    "# i.e., call a model, WaveGlow, from the NVIDIA DeepLearningExamples repository. \n",
    "waveglow = torch.hub.load( 'nvidia/DeepLearningExamples:torchhub', \n",
    "                            'nvidia_waveglow'\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/doranlyong/.cache/torch/hub/nvidia_DeepLearningExamples_torchhub\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['nvidia_ssd',\n",
       " 'nvidia_ssd_processing_utils',\n",
       " 'nvidia_tacotron2',\n",
       " 'nvidia_tts_utils',\n",
       " 'nvidia_waveglow']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To explore all the available API endpoints of a particular repository \n",
    "# This lists all the models available in the 'nvidia/DeepLearningExamples:torchhub' repo. \n",
    "\n",
    "torch.hub.list( 'nvidia/DeepLearningExamples:torchhub' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Design - custom NN model (p.71)\n",
    "using PyTorch NN module; ```torch.nn```\n",
    "\n",
    "Consist of :\n",
    "* input layer \n",
    "* hidden layer \n",
    "* output layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()   # super() function to execute the parent nn.Module class's __init__() method \n",
    "                                            # to initialize the class parameters. \n",
    "\n",
    "        self.fc1 = nn.Linear( in_features=2048, out_features=256 ) # (ref) https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "        self.fc2 = nn.Linear( 256, 64 )\n",
    "        self.fc3 = nn.Linear( 64, 2 )\n",
    "\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor: # Define how the model processes data \n",
    "        assert x.dim() == 4, f\"Input tensor to temporal convolution must be 4d! but, {x.dim()}d tensor is given\"\n",
    "        \n",
    "        x = x.view(-1, 2048)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNet(\n",
      "  (fc1): Linear(in_features=2048, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# instantiating the model object \n",
    "\n",
    "model = SimpleNet() # Instantiate, or create the model\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1938,  0.1466],\n",
      "        [-0.1824,  0.1057],\n",
      "        [-0.1688,  0.1187],\n",
      "        [-0.1095,  0.1547]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.rand(4, 1, 1, 2048)  # (batch, channel, height, width)\n",
    "score = model(input)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training (p.85) \n",
    "* training CIFAR-10 with ```LeNet5``` by ```Yann LeCun``` in the 1990s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class LeNet5(nn.Module): \n",
    "    def __init__(self): \n",
    "        super(LeNet5, self).__init__() \n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5) # (ref) https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(in_features=16*5*5, out_features=120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        assert x.dim() == 4, f\"Input tensor to temporal convolution must be 4d! but, {x.dim()}d tensor is given\"\n",
    "\n",
    "        x = F.max_pool2d( F.relu(self.conv1(x)), \n",
    "                          (2,2), # kernel size \n",
    "                        )\n",
    "        x = F.max_pool2d( F.relu(self.conv2(x)), 2 )\n",
    "#        print(x.shape)  # e.g., (4, 3, 32, 32) -> (4, 16, 5, 5)\n",
    "        x = x.view(-1, int(x.nelement() / x.shape[0]))  # num_elements / batch_size \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/doranlyong/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "model = LeNet5().to(device) # Instantiate, or create the model\n",
    "\n",
    "# === TEST === # \n",
    "input = torch.rand(4, 3, 32, 32)  # (batch, channel, height, width)\n",
    "score = model(input.to(device))\n",
    "\n",
    "print(score.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamental Training Loop \n",
    "\n",
    "* define the loss function (called the ```criterion```)\n",
    "* define optimizer algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "optimizer = optim.SGD( model.parameters(), # (!) be sure to pass in the model.parameters() \n",
    "                        lr=1e-3, \n",
    "                        momentum=0.9,\n",
    "                     ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0, Avg_loss: 1.9350018263244628\n",
      " Epoch: 1, Avg_loss: 1.5838120969200133\n",
      " Epoch: 2, Avg_loss: 1.4504999675750732\n",
      " Epoch: 3, Avg_loss: 1.361796992111206\n",
      " Epoch: 4, Avg_loss: 1.3011036464309693\n",
      " Epoch: 5, Avg_loss: 1.254812949333191\n",
      " Epoch: 6, Avg_loss: 1.2209006089878083\n",
      " Epoch: 7, Avg_loss: 1.1894887944412231\n",
      " Epoch: 8, Avg_loss: 1.160944178981781\n",
      " Epoch: 9, Avg_loss: 1.1359832714271545\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10 \n",
    "\n",
    "for epoch in range(EPOCHS): \n",
    "\n",
    "    model.train() # set train mode \n",
    "    batch_loss = 0.0 \n",
    "\n",
    "    for inputs, labels in trainloader: \n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # === forward \n",
    "        scores = model(inputs)\n",
    "        loss = criterion(scores, labels)\n",
    "        \n",
    "\n",
    "        # === backward \n",
    "        optimizer.zero_grad() # Zero out gradients before each backpropagation pass, or they'll accumulate. \n",
    "        loss.backward() \n",
    "\n",
    "\n",
    "        # === gradient descent, and step \n",
    "        optimizer.step() \n",
    "\n",
    "        # === accumulate batch loss \n",
    "        batch_loss += loss.item() \n",
    "\n",
    "    print(f\" Epoch: {epoch}, Avg_loss: {batch_loss / len(trainloader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation (p.94)\n",
    "* Splitting Training Dataset into Training & Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "625\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split \n",
    "\n",
    "train_set, val_set = random_split(  train_data, \n",
    "                                    [40000, 10000], \n",
    "                                )\n",
    "\n",
    "trainloader = DataLoader(   train_set,     # p.62\n",
    "                            batch_size=16, \n",
    "                            shuffle=True, \n",
    "                            num_workers=3, \n",
    "                        )\n",
    "\n",
    "valloader = DataLoader( val_set,\n",
    "                        batch_size=16, \n",
    "                        shuffle=True,\n",
    "                        num_workers=3\n",
    "                       )  \n",
    "\n",
    "print(len(trainloader))    # 16 * 2500 = 40000                 \n",
    "print(len(valloader))      # 16 * 625 = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training loop with validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "model = LeNet5().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.SGD(  model.parameters(), \n",
    "                        lr=1e-3, \n",
    "                        momentum=0.9, \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, avg_TrainLoss: 2.0477127197265625, avg_ValLoss: 1.8506497562408448\n",
      "Epoch: 1, avg_TrainLoss: 1.6999339406967162, avg_ValLoss: 1.6265272552490235\n",
      "Epoch: 2, avg_TrainLoss: 1.5589246153116225, avg_ValLoss: 1.5205268508911134\n",
      "Epoch: 3, avg_TrainLoss: 1.476604621744156, avg_ValLoss: 1.4567375440597534\n",
      "Epoch: 4, avg_TrainLoss: 1.4093870484113693, avg_ValLoss: 1.3948649516105651\n",
      "Epoch: 5, avg_TrainLoss: 1.3653048881530763, avg_ValLoss: 1.3376896905899047\n",
      "Epoch: 6, avg_TrainLoss: 1.321136818766594, avg_ValLoss: 1.3044609288215636\n",
      "Epoch: 7, avg_TrainLoss: 1.2820677130937577, avg_ValLoss: 1.30562296333313\n",
      "Epoch: 8, avg_TrainLoss: 1.2574018606305122, avg_ValLoss: 1.2835068096160889\n",
      "Epoch: 9, avg_TrainLoss: 1.23261748752594, avg_ValLoss: 1.2740140192985534\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10 \n",
    "\n",
    "for epoch in range(EPOCHS): \n",
    "\n",
    "    # === Training === # \n",
    "    model.train() \n",
    "    train_loss = 0.0 \n",
    "\n",
    "    for inputs, labels in trainloader: \n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # === forward \n",
    "        score = model(inputs)\n",
    "        loss = criterion(score, labels)\n",
    "\n",
    "        # === backward \n",
    "        optimizer.zero_grad() \n",
    "        loss.backward() \n",
    "\n",
    "        # === gradient descent, and step \n",
    "        optimizer.step() \n",
    "\n",
    "\n",
    "        # === accumulate batch loss \n",
    "        train_loss += loss.item() \n",
    "\n",
    "    \n",
    "    # === Validation === # \n",
    "    model.eval() \n",
    "    val_loss = 0.0 \n",
    "\n",
    "    for inputs, labels in valloader: \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # === forward \n",
    "        score = model(inputs)\n",
    "        loss = criterion(score, labels)\n",
    "\n",
    "        # === accumulate batch loss \n",
    "        val_loss += loss.item() \n",
    "\n",
    "    \n",
    "    print(f\"Epoch: {epoch}, avg_TrainLoss: {train_loss/len(trainloader)}, avg_ValLoss: {val_loss/len(valloader)}\")\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing (p.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_batches: 625, batch_size: 16\n",
      "Test ACC: 0.582\n"
     ]
    }
   ],
   "source": [
    "model.eval() \n",
    "num_correct = 0.0 \n",
    "\n",
    "for inputs, labels in testloader: \n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # inference \n",
    "    score = model(inputs)\n",
    "    score_max, idx = torch.max(score, 1) # select the class index with the highest score \n",
    "\n",
    "    # check correct\n",
    "    num_correct += ( idx == labels).float().sum() # compare the prediction to the true label \n",
    "                                                  # and count the number of correct predictions. \n",
    "\n",
    "\n",
    "# === Performance metric === # \n",
    "Acc = num_correct / (len(testloader) * testloader.batch_size)\n",
    "\n",
    "print(f\"num_batches: {len(testloader)}, batch_size: {testloader.batch_size}\")\n",
    "print(f\"Test ACC: {Acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment (p.98)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Models & Loading the Parameters \n",
    "* ```state_dict()```\n",
    "* ```load_state_dict```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save( model.state_dict(), \"./lenet5_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload \n",
    "model = LeNet5().to(device) \n",
    "model.load_state_dict( torch.load(\"./lenet5_model.pth\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy to PyTorch Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependencies = ['torch']\n",
    "from torchvision.models.vgg import vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependencies = ['torch']\n",
    "from torchvision.models.vgg import vgg16 as _vgg16\n",
    "\n",
    "# vgg16 is the name of the entrypoint \n",
    "def vgg16(pretrained=False, **kwargs):\n",
    "    \"\"\"\n",
    "        This docstring shows up in hub.help() VGG16 model\n",
    "        pretrained (bool): kwargs, load pretrained weights into the model\n",
    "\n",
    "    \"\"\"\n",
    "    # Call the model, load pretrained weights\n",
    "    model = _vgg16(pretrained=pretrained, **kwargs)\n",
    "    return model "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4b8843b2ce6a124445f967608eb4b7f6f94f33a6ef75c0de5d26718ab1266eb6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}